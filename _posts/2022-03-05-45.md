---
title: 20220305
layout: post
---

Listened to part of this really interesting talk with Alan Kay (FWIW I think everything I've listened to of his or read of his is very interesting). I love how computer pioneers talk about the way they view computers. He was expressing dislike for how computer science research institutes don't make their own hardware really anymore. My immediate thought was that the hardware has become too complex and the necessary knowledge required is too distributed + it became cheaper to use standard hardware. His rationale for this was that you don't just make faster computers, you try radically different hardware in order to test out new ideas. Instead we've become too complacent with "normal" and are forgetting how much freedom we have in making computers and what they can be. 

I think I've either wrote about my thoughts related to this here or in my journal last year, but this was a really eye opening idea for me while reading [*The Dream Machine*](https://www.goodreads.com/en/book/show/722412). I'll briefly rehash my epiphany here. I realized that since I had been born computers had existed in some stable form and I grew up using them in elementary and the way that we use them now in 2022 when I'm a young adult is mostly the same with some speed improvements and new apps. But fundamentally we aren't using computers in any radical new way. The "holy shit" moment (to use an Alan Kay phrase) was while reading that book and seeing how many of these common user interfaces and paradigms existed in the 60s! Despite having a degree in Computer Science I did not know this and thought certain things, like touch screens, were fairly novel. Digital handwriting technology existed in the early 60s even - its seriously bonkers how much happened and existed in the 60s and its seemingly *never taught*. Alan Kay talks about how Computer Science isn't a proper science yet and I more and more agree. In every "science" class I took we learned about the history of the field and the fundamental experiments that led to our modern understanding of the field. In computer science we just talk about our understanding of the current state of the field without too much context (at least that was how my education went). The "holy shit" moment was realizing that these pioneers were born at a time where computers did not exist in the way they do now. They had no conceptions of "normal" computing except for maybe batch processing/differential analyzers depending on how young they were. They had to come up with what a computer should be and how one should use it. They weren't alone at PARC doing this as there were many other groups, but they were all a part of the larger ARPA community and collectively came up with the ideas. But Kay's point is that that idea generation from that fundamental level has mostly stalled as we've gotten used to this "normal" paradigm of computing. I want to read more of Kay's thoughts including [this NSF proposal](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.97.4939&rep=rep1&type=pdf) he got funded for, and [what (if anything) came of it](http://www.vpri.org/pdf/tr2012001_steps.pdf). 

I think this is an area that I would like to help make progress towards improving, and educating people how they can think more in these "out of the box" ways to come up with new progress and not get stuck in normal patterns.

---

**Daily Listening**

A throwback to a [middle school music](https://open.spotify.com/track/2lVLgsRENLhr7lCq88udyX?si=2ca453971cc042b1). Classic background music for playing Runescape ðŸ˜‚

**Daily Reading**

I didn't read anything today somehow! ðŸ˜¬